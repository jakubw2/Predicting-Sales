{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This notebook is a template to give directions on our expectations and serve as a proxy for a rubric as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have any packages or libraries that you would like to pre-load, put them here (next cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dmba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c051f4de2974>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdmba\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregressionSummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madjusted_r2_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAIC_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBIC_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dmba'"
     ]
    }
   ],
   "source": [
    "# Packages and libraries load here [basic packages are specified; additional packages may be needed]\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import missingno as msno\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "import matplotlib.pylab as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from dmba import regressionSummary, adjusted_r2_score, AIC_score, BIC_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data set here\n",
    "data_df = pd.read_csv('../resource/lib/public/project_data.csv')\n",
    "\n",
    "test_df = pd.read_csv('../resource/lib/public/project_leaderboard_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform initial inspection of the data (add as many cells as you need).\n",
    "Aspects may include:\n",
    "\n",
    "1. Cursory look at the rows and columns\n",
    "2. Inspect the datatypes of the attributes and response\n",
    "3. Counts of the observations and variables\n",
    "4. Summary statistics of each variable\n",
    "5. Discussion or Insights from the exploration above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial inspection begins here\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(columns=['PANID'], inplace=True)\n",
    "data_df.columns = [c.replace(' ', '_') for c in data_df.columns]\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal vs Nominal values. \n",
    "## Here the output of the dataset shows data types. Most of these predictors are sales, which are ordinal. It seems the nominal variables are household head race and marital status. This makes sense because they are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(columns=['PANID'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform data visualization (add as many cells as you need). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Aspects may include:\n",
    "\n",
    "1. Scatter plots for at least four relevant bivariate relationships.\n",
    "2. Distribution plots for at least two relevant numeric variables\n",
    "3. Box plots for at least two numerical-categorical relationships.\n",
    "4. Bar charts for at least two interesting relationships.\n",
    "5. Include discussions why you selected the plots/charts along with the outputs\n",
    "6. Share insights that you gain from these plots, in context of the value to a business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization begins here\n",
    "#numerical \n",
    "\n",
    "x=np.log(data_df['beer_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual spending on beer\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['milk_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual spending on milk\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['blades_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual spending on Blades\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['carbbev_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on carbonated beverages\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['cigets_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y) \n",
    "plt.xlabel(\"Annual Spending on cigarettes\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['coffee_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Coffee\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['coldcer_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Cold Cereal\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['deod_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Deodorant\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['diapers_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Diapers\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['factiss_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Factiss\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['fzdinent_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Frozen Dinners\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['fzpizza_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Frozen Pizzas\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['hhclean_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Household Cleaning\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['hotdog_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Hot Dogs\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['laundet_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Laundry Detergent\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['margbutr_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Margarine Butter\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['mayo_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Mayonaise\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['mustketc_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Mustard and Ketchup\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['paptowls_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Paper Towels\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['peanbutr_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Peanut Butter\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['photo_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Photos\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['razors_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Razors\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['shamp_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Shampoo\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "x=np.log(data_df['soup_spending']+1)\n",
    "y=np.log(data_df['saltsnck_spending']+1)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"Annual Spending on Soup\")\n",
    "plt.ylabel(\"Salty Snack Spending\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=data_df.boxplot(column = 'saltsnck_spending', by = 'Family_Size')\n",
    "ax.set_ylabel(\"Salty Snack Spending\")\n",
    "ax.set_yscale('log')\n",
    "plt.suptitle(\" \")\n",
    "plt.title(\" \")\n",
    "plt.show()\n",
    "\n",
    "ax=data_df.boxplot(column = 'saltsnck_spending', by = 'Combined_Pre-Tax_Income_of_HH')\n",
    "ax.set_ylabel(\"Salty Snack Spending\")\n",
    "ax.set_yscale('log')\n",
    "plt.suptitle(\" \")\n",
    "plt.title(\" \")\n",
    "plt.show()\n",
    "\n",
    "ax=data_df.boxplot(column = 'saltsnck_spending', by = 'ALL_TVS')\n",
    "ax.set_ylabel(\"Salty Snack Spending\")\n",
    "ax.set_yscale('log')\n",
    "plt.suptitle(\" \")\n",
    "plt.title(\" \")\n",
    "plt.show()\n",
    "\n",
    "ax=data_df.boxplot(column = 'saltsnck_spending', by = 'Age_Group_Applied_to_Household_Head')\n",
    "ax.set_ylabel(\"Salty Snack Spending\")\n",
    "ax.set_yscale('log')\n",
    "plt.suptitle(\" \")\n",
    "plt.title(\" \")\n",
    "plt.show()\n",
    "\n",
    "ax=data_df.boxplot(column = 'saltsnck_spending', by = 'Age_Group_Applied_to_Male_HH')\n",
    "ax.set_ylabel(\"Salty Snack Spending\")\n",
    "ax.set_yscale('log')\n",
    "plt.suptitle(\" \")\n",
    "plt.title(\" \")\n",
    "plt.show()\n",
    "\n",
    "ax=data_df.boxplot(column = 'saltsnck_spending', by = 'Age_Group_Applied_to_Female_HH')\n",
    "ax.set_ylabel(\"Salty Snack Spending\")\n",
    "ax.set_yscale('log')\n",
    "plt.suptitle(\" \")\n",
    "plt.title(\" \")\n",
    "plt.show()\n",
    "\n",
    "ax=data_df.boxplot(column = 'saltsnck_spending', by = 'Number_of_Cats')\n",
    "ax.set_ylabel(\"Salty Snack Spending\")\n",
    "ax.set_yscale('log')\n",
    "plt.suptitle(\" \")\n",
    "plt.title(\" \")\n",
    "plt.show()\n",
    "\n",
    "ax=data_df.boxplot(column = 'saltsnck_spending', by = 'Children_Group_Code')\n",
    "ax.set_ylabel(\"Salty Snack Spending\")\n",
    "ax.set_yscale('log')\n",
    "plt.suptitle(\" \")\n",
    "plt.title(\" \")\n",
    "plt.show()\n",
    "\n",
    "ax=data_df.boxplot(column = 'saltsnck_spending', by = 'Education_Level_Reached_by_Household_Head')\n",
    "ax.set_ylabel(\"Salty Snack Spending\")\n",
    "ax.set_yscale('log')\n",
    "plt.suptitle(\" \")\n",
    "plt.title(\" \")\n",
    "plt.show()\n",
    "\n",
    "ax=data_df.boxplot(column = 'saltsnck_spending', by = \"Education_Level_Reached_by_Female_HH\")\n",
    "ax.set_ylabel(\"Salty Snack Spending\")\n",
    "ax.set_yscale('log')\n",
    "plt.suptitle(\" \")\n",
    "plt.title(\" \")\n",
    "plt.show()\n",
    "\n",
    "ax=data_df.boxplot(column = 'saltsnck_spending', by = 'Marital_Status')\n",
    "ax.set_ylabel(\"Salty Snack Spending\")\n",
    "ax.set_yscale('log')\n",
    "plt.suptitle(\" \")\n",
    "plt.title(\" \")\n",
    "plt.show()\n",
    "\n",
    "ax=data_df.boxplot(column = 'saltsnck_spending', by = 'Household_Head_Race')\n",
    "ax.set_ylabel(\"Salty Snack Spending\")\n",
    "ax.set_yscale('log')\n",
    "plt.suptitle(\" \")\n",
    "plt.title(\" \")\n",
    "plt.show()\n",
    "\n",
    "ax=data_df.boxplot(column = 'saltsnck_spending', by = 'Type_of_Residential_Possession')\n",
    "ax.set_ylabel(\"Salty Snack Spending\")\n",
    "ax.set_yscale('log')\n",
    "plt.suptitle(\" \")\n",
    "plt.title(\" \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One thing apparent from the scatter plots is that the data is not normally distrbuted. It is necessary to log the data to see any type of correlation. Generally, salty snacks exhibits a positive correlation with most other numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Pairwise Correlations and comment below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pairwise correlations and comment here\n",
    "from pandas.plotting import scatter_matrix\n",
    "_ = scatter_matrix(data_df[['saltsnck_spending', 'Combined_Pre-Tax_Income_of_HH', 'beer_spending', 'milk_spending','Marital_Status']], figsize=(6, 6), diagonal='kde')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr= data_df.corr()\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It seems that most variables do not have high correlations. This helps when creating models, avoiding instability. Household head is highly correlated with groups applied to household head, and all TVs, to name a few. These relationships are deemed insignificant and can be removed to avoid overcomplicating the model.\n",
    "\n",
    "## For the variables that also are not at all correlated or affect the response variable significantly are removed via a variable threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msno.heatmap(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values and comment below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'miss.val': data_df.isnull().sum(), })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect categorical variables here (add as many cells as you need) \n",
    "Aspects may include:\n",
    "1. Counts of each subtype of categorical variables\n",
    "2. Analysis of each categorical variable as nominal or ordinal\n",
    "3. Discussion or comments for each of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect categorical variables here\n",
    "data_df['Age_Group_Applied_to_Female_HH'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Combined_Pre-Tax_Income_of_HH'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['ALL_TVS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Family_Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Age_Group_Applied_to_Household_Head'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Age_Group_Applied_to_Male_HH'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Age_Group_Applied_to_Female_HH'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Number_of_Cats'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Age_Group_Applied_to_Household_Head'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Children_Group_Code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Education_Level_Reached_by_Household_Head'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Education_Level_Reached_by_Female_HH'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Marital_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Household_Head_Race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Type_of_Residential_Possession'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['beer_spending'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The sections above were all about Exploratory Data analysis. These were to be done in teams\n",
    "# The following sections should be done independently. You can copy the notebooks and create one for each team member"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X and y objects to hold the predictors and response variable, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('../resource/lib/public/project_data.csv')\n",
    "\n",
    "test_df = pd.read_csv('../resource/lib/public/project_leaderboard_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PANID = test_df['PANID']\n",
    "\n",
    "PANID = pd.Series(PANID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(columns=['PANID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(columns=['PANID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_df['saltsnck_spending']\n",
    "X = data_df.drop(columns=['saltsnck_spending'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical variables here \n",
    "Aspects may include:\n",
    "1. Dummy coding (one-hot encoding) nominal variables\n",
    "2. Label encoding for ordinal variables. This is already done in the dataset,but do verify this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode Categorical variable\n",
    "X = pd.get_dummies(X, prefix_sep='_', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.get_dummies(test_df, prefix_sep='_', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fancyimpute import KNN\n",
    "X = KNN(k=5).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fancyimpute import KNN\n",
    "test_df = KNN(k=5).fit_transform(test_df)\n",
    "#project_leaderboard_df = KNN(k=5).fit_transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and validation subsets \n",
    "(optional; used to quickly test models with a small validation set of no more than 10% of the full dataset)\n",
    "### NOTE: The project_Leaderboard dataset is used to generate response estimates for submitting to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data here. \n",
    "#train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.1, random_state=1)     #stratify=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are any variables that have less than 1% variance, we'll remove them now\n",
    "# With 1,000 samples, this equates to 10 changes in value, the absolute minimum required for modeling\n",
    "#from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "#selector = VarianceThreshold(0.009)\n",
    "\n",
    "#train_X = selector.fit_transform(train_X)\n",
    "#valid_X = selector.transform(valid_X)\n",
    "#test_df = selector.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(0.009)\n",
    "\n",
    "X = selector.fit_transform(X)\n",
    "test_df = selector.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)\n",
    "test_df = pd.DataFrame(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-model data processing\n",
    "fit_transform on the training data, transform on the test data to maintain information in-\n",
    "tegrity of the test data Aspects may include:\n",
    "1. Standardization or normalization of the predictor values\n",
    "2. Transformations of predictors or response (eg., Box-Cox, log, square root) \n",
    "3. Using a variance threshold to feature select predictors\n",
    "4. Discussion or comments for each of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc = StandardScaler()\n",
    "#transform_train_X = sc.fit_transform(train_X)\n",
    "#transform_valid_X = sc.transform(valid_X)\n",
    "\n",
    "#test_df = sc.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform_train_X = pd.DataFrame(transform_train_X)\n",
    "#transform_valid_X = pd.DataFrame(transform_valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a logistic regression (set penalty=l2 and C=1e42 to avoid regularization)\n",
    "E_Net = ElasticNetCV(normalize= False,l1_ratio=(0.9, 0.95, 0.99, 1), n_alphas=50, cv=10,)\n",
    "E_Net.fit(X, y)\n",
    "\n",
    "regressionSummary(y, E_Net.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm definition and model building here\n",
    "Build at least three models. Justify the model you select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building here \n",
    "#1.linear regression\n",
    "#2.elastic net\n",
    "#3.ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression model\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#linear_reg = LinearRegression()\n",
    "#linear_reg.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = LinearRegression()\n",
    "\n",
    "# fit the linear regression algorithm object to the training data, thus creating a model\n",
    "data_lm.fit(X, y)\n",
    "\n",
    "# print coefficients from the training data\n",
    "print('intercept ', data_lm.intercept_)\n",
    "print(pd.DataFrame({'Predictor': X.columns, 'coefficient': data_lm.coef_}))\n",
    "\n",
    "# print performance measures of the training data\n",
    "regressionSummary(y, data_lm.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet w/CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "project_lasso = ElasticNetCV(normalize=True, l1_ratio=[.1,.5,.7,.9,.95,.99,1], cv=5, n_alphas=80, max_iter=1000)\n",
    "project_lasso.fit(X,y)\n",
    "\n",
    "#train_X = pd.DataFrame(train_X)\n",
    "\n",
    "#print coefficients\n",
    "print('intercept', project_lasso.intercept_)\n",
    "print(pd.DataFrame({'Predictor': X.columns, 'coefficient': project_lasso.coef_}))\n",
    "\n",
    "# print performance measures of the training data\n",
    "regressionSummary(y, project_lasso.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, BayesianRidge\n",
    "\n",
    "ridge_cv = RidgeCV(normalize=False, alphas=(0.01, 0.1, 0.3, 0.5, 0.7, 1.0), cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "ridge_cv.fit(X, y)\n",
    "\n",
    "print(\"RidgeCV Model\")\n",
    "regressionSummary(y, ridge_cv.predict(X))\n",
    "\n",
    "print('Ridge-CV chosen regularization: ', ridge_cv.alpha_)\n",
    "print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate performance information and analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear\n",
    "pred_y1 = data_lm.predict(test_df)\n",
    "\n",
    "print(pred_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elasticnet\n",
    "pred_y2 = project_lasso.predict(test_df)\n",
    "\n",
    "print(pred_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridgeregression\n",
    "pred_y3 = ridge_cv.predict(test_df)\n",
    "\n",
    "print(pred_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y3 = pd.DataFrame(pred_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard_pred = ridge_cv.predict(test_df)\n",
    "\n",
    "leaderboard_pred = pd.Series(leaderboard_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([PANID, leaderboard_pred],axis =1)\n",
    "\n",
    "final_df = final_df.rename(columns={0:'Predicted'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('Ridge_pred.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
